name: Stage 3 Network Feature Extraction Workflow

on:
  workflow_dispatch:
  # schedule:
  #   - cron: "0 3 * * *"

jobs:
  run-network-extraction:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        dataset: [phiusiil, mendeley]
        include:
          - dataset: phiusiil
            input_pattern: "*PhiUSIIL_cleaned_v2.csv"
          - dataset: mendeley
            input_pattern: "*Mendeley_cleaned_v2.csv"

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.MTECH }} # Use your PAT for write access
          fetch-depth: 0 # Get full history for proper git operations

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install aiohttp aiodns pandas tldextract beautifulsoup4 python-whois lxml

      - name: Define Paths, Find Input File, and Generate Output Path
        id: setup
        run: |
          INPUT_DIR="lexical_features"
          OUTPUT_DIR="network_data_with_lexical_features"
          PYTHON_SCRIPT="network_feature_extractor.py"
          INPUT_PATTERN="${{ matrix.input_pattern }}"

          mkdir -p "$INPUT_DIR"
          mkdir -p "$OUTPUT_DIR"

          # Find the latest file matching the pattern for the current dataset
          LATEST_INPUT_FILE=$(find "$INPUT_DIR" -maxdepth 1 -name "$INPUT_PATTERN" -printf '%T@ %p\n' | sort -n | tail -n 1 | cut -d' ' -f2-)

          if [ -z "$LATEST_INPUT_FILE" ]; then
            echo "::error::No file matching pattern '$INPUT_PATTERN' found in '$INPUT_DIR'."
            exit 1
          fi

          # Generate output filename based on input filename
          INPUT_BASENAME=$(basename "$LATEST_INPUT_FILE")
          OUTPUT_FILENAME="network_features_${INPUT_BASENAME}"
          OUTPUT_FILE_PATH="$OUTPUT_DIR/$OUTPUT_FILENAME"

          echo "LATEST_INPUT_FILE=$LATEST_INPUT_FILE" >> $GITHUB_OUTPUT
          echo "OUTPUT_FILE_PATH=$OUTPUT_FILE_PATH" >> $GITHUB_OUTPUT
          echo "PYTHON_SCRIPT_PATH=$PYTHON_SCRIPT" >> $GITHUB_OUTPUT

      - name: Run Network Feature Extraction for ${{ matrix.dataset }}
        run: |
          python "${{ steps.setup.outputs.PYTHON_SCRIPT_PATH }}" \
            --input-file "${{ steps.setup.outputs.LATEST_INPUT_FILE }}" \
            --output-file "${{ steps.setup.outputs.OUTPUT_FILE_PATH }}"

      - name: Upload Network Features for ${{ matrix.dataset }}
        uses: actions/upload-artifact@v4
        with:
          name: network_features_${{ matrix.dataset }}_${{ github.run_id }}
          path: ${{ steps.setup.outputs.OUTPUT_FILE_PATH }}
          if-no-files-found: error

      - name: Commit and Push Network Feature Files
        env:
          GITHUB_TOKEN: ${{ secrets.MTECH }} # Use PAT for authentication
        run: |
          # Configure git with your personal credentials
          git config user.name "Ifeoluwa Oseni"
          git config user.email "ifeoseni@gmail.com"

          # Pull latest changes to avoid conflicts
          git pull origin main --rebase

          # Add changes
          git add network_data_with_lexical_features/

          # Check for changes before committing
          if git diff --cached --quiet; then
            echo "No changes to commit for ${{ matrix.dataset }}"
          else
            git commit -m "Auto-update: Network features for ${{ matrix.dataset }} [skip ci]"
            git push origin HEAD:main
            echo "Changes pushed successfully"
          fi
