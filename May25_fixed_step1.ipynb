{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_vfWBHR62ydE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP is working correctly!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "import shap\n",
    "print(\"SHAP is working correctly!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# First split: 70% train, 30% temp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m X_train, X_temp, y_train, y_temp = train_test_split(\u001b[43mX\u001b[49m, y, test_size=\u001b[32m0.30\u001b[39m, random_state=\u001b[32m42\u001b[39m, stratify=y)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Second split: 15% validation, 15% test from the remaining 30%\u001b[39;00m\n\u001b[32m      7\u001b[39m X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=\u001b[32m0.5\u001b[39m, random_state=\u001b[32m42\u001b[39m, stratify=y_temp)\n",
      "\u001b[31mNameError\u001b[39m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"lexical_features/lexical_features_20250525_184014.csv\")  # e.g., \"remove_duplicate_from_combined_dataset.csv\"\n",
    "\n",
    "# Separate features (X) and target label (y)\n",
    "X = df.drop(columns=[\"label\", \"url\", \"source\"], errors='ignore')  # Drop non-feature columns\n",
    "y = df[\"label\"]\n",
    "\n",
    "# First split: 70% train, 30% temp\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
    "\n",
    "# Second split: 15% validation, 15% test from remaining 30%\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "print(f\"Train: {len(X_train)}, Validation: {len(X_val)}, Test: {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qw20QUaL3RfU",
    "outputId": "a0753fab-fe04-47fc-a974-29a24d095a6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully. Shape: (665795, 53)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('lexical_features/lexical_features_20250525_184014.csv')\n",
    "print(\"Data loaded successfully. Shape:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SsJp3mer3djr",
    "outputId": "fce90e3d-458d-486f-da6f-d50ebb1dd50f"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'is_active'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'is_active'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Filter out inactive rows\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_active\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Separate features and target\u001b[39;00m\n\u001b[0;32m      5\u001b[0m X \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdomain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_active\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'is_active'"
     ]
    }
   ],
   "source": [
    "# Filter out inactive rows\n",
    "df = df[df['is_active'] == 1]\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=['label', 'domain', 'is_active'])\n",
    "y = df['label']\n",
    "\n",
    "# Handle numeric/non-numeric columns\n",
    "numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "X = X[numeric_cols]  # Drop non-numeric columns\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "X = pd.DataFrame(X_imputed, columns=X.columns)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "print(\"Data preprocessing completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GyVg_edG3ksN",
    "outputId": "49a7b31a-c480-4d8c-8554-f6e8842a2558"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training models...\n",
      "All models trained successfully.\n"
     ]
    }
   ],
   "source": [
    "# Initialize models\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "svm = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "xgb = XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "\n",
    "# Train individual models\n",
    "print(\"Training models...\")\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "xgb.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Create ensemble\n",
    "ensemble = VotingClassifier(estimators=[\n",
    "    ('rf', rf),\n",
    "    ('svm', svm),\n",
    "    ('xgb', xgb)\n",
    "], voting='soft')\n",
    "ensemble.fit(X_train_scaled, y_train)\n",
    "print(\"All models trained successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qq2lWMQF3nz1",
    "outputId": "9935144c-a87f-4a52-9423-4dfacfa763fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Evaluation Results:\n",
      "           Model  Accuracy  Precision    Recall  F1 Score   ROC AUC\n",
      "0  Random Forest  0.824074   0.968750  0.632653  0.765432  0.932722\n",
      "1            SVM  0.842593   0.880952  0.755102  0.813187  0.908682\n",
      "2        XGBoost  0.824074   0.788462  0.836735  0.811881  0.909201\n",
      "3       Ensemble  0.833333   0.844444  0.775510  0.808511  0.936700\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    y_pred = (model.predict_proba(X_test)[:, 1] >= 0.5).astype(int)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall': recall_score(y_test, y_pred),\n",
    "        'F1 Score': f1_score(y_test, y_pred),\n",
    "        'ROC AUC': roc_auc_score(y_test, y_prob),\n",
    "        'Confusion Matrix': confusion_matrix(y_test, y_pred)\n",
    "    }\n",
    "\n",
    "# Evaluate all models\n",
    "results = pd.DataFrame([\n",
    "    evaluate_model(rf, X_test_scaled, y_test, 'Random Forest'),\n",
    "    evaluate_model(svm, X_test_scaled, y_test, 'SVM'),\n",
    "    evaluate_model(xgb, X_test_scaled, y_test, 'XGBoost'),\n",
    "    evaluate_model(ensemble, X_test_scaled, y_test, 'Ensemble')\n",
    "])\n",
    "\n",
    "print(\"\\nModel Evaluation Results:\")\n",
    "print(results.drop(columns=['Confusion Matrix']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P86iUVRBORDV",
    "outputId": "b8096ad2-a5b1-45dd-ef27-42afad3ff062"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Evaluate all models with their respective thresholds\u001b[39;00m\n\u001b[0;32m     42\u001b[0m evaluation_results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, model \u001b[38;5;129;01min\u001b[39;00m [(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRandom Forest\u001b[39m\u001b[38;5;124m'\u001b[39m, rf),\n\u001b[0;32m     44\u001b[0m                          (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSVM\u001b[39m\u001b[38;5;124m'\u001b[39m, svm),\n\u001b[0;32m     45\u001b[0m                          (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mXGBoost\u001b[39m\u001b[38;5;124m'\u001b[39m, xgb),\n\u001b[0;32m     46\u001b[0m                          (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnsemble\u001b[39m\u001b[38;5;124m'\u001b[39m, ensemble)]:\n\u001b[0;32m     47\u001b[0m     result \u001b[38;5;241m=\u001b[39m evaluate_model(\n\u001b[0;32m     48\u001b[0m         model,\n\u001b[0;32m     49\u001b[0m         X_test_scaled,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     52\u001b[0m         threshold\u001b[38;5;241m=\u001b[39mmodel_thresholds[model_name]\n\u001b[0;32m     53\u001b[0m     )\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rf' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, model_name, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Evaluate model performance with customizable probability threshold\n",
    "\n",
    "    Parameters:\n",
    "    - model: Trained model\n",
    "    - X_test: Test features\n",
    "    - y_test: True labels\n",
    "    - model_name: Name of the model\n",
    "    - threshold: Probability threshold for classification (default=0.5)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "        return {\n",
    "            'Model': model_name,\n",
    "            'Threshold': threshold,\n",
    "            'Accuracy': accuracy_score(y_test, y_pred),\n",
    "            'Precision': precision_score(y_test, y_pred, zero_division=0),\n",
    "            'Recall': recall_score(y_test, y_pred),\n",
    "            'F1 Score': f1_score(y_test, y_pred),\n",
    "            'ROC AUC': roc_auc_score(y_test, y_prob),\n",
    "            'Confusion Matrix': confusion_matrix(y_test, y_pred),\n",
    "            'Positive Rate': y_pred.mean()  # Percentage of positive predictions\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating {model_name}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Define custom thresholds for each model\n",
    "model_thresholds = {\n",
    "    'Random Forest': 0.43,   # Default threshold\n",
    "    'SVM': 0.59,            # SVM often needs lower threshold\n",
    "    'XGBoost': 0.45,       # Slightly more conservative\n",
    "    'Ensemble': 0.55        # Default threshold\n",
    "}\n",
    "\n",
    "# Evaluate all models with their respective thresholds\n",
    "evaluation_results = []\n",
    "for model_name, model in [('Random Forest', rf),\n",
    "                         ('SVM', svm),\n",
    "                         ('XGBoost', xgb),\n",
    "                         ('Ensemble', ensemble)]:\n",
    "    result = evaluate_model(\n",
    "        model,\n",
    "        X_test_scaled,\n",
    "        y_test,\n",
    "        model_name,\n",
    "        threshold=model_thresholds[model_name]\n",
    "    )\n",
    "    if result is not None:\n",
    "        evaluation_results.append(result)\n",
    "\n",
    "# Create results DataFrame\n",
    "results = pd.DataFrame(evaluation_results)\n",
    "\n",
    "# Print formatted results\n",
    "print(\"\\nModel Evaluation Results with Custom Thresholds:\")\n",
    "print(results.drop(columns=['Confusion Matrix']).to_string(index=False))\n",
    "\n",
    "# Optional: Display confusion matrices separately\n",
    "print(\"\\nConfusion Matrices:\")\n",
    "for _, row in results.iterrows():\n",
    "    print(f\"\\n{row['Model']} (Threshold={row['Threshold']}):\")\n",
    "    print(row['Confusion Matrix'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "94AlEh8fQBqq",
    "outputId": "398b54af-1bf8-436c-d4b2-c07a0bad4504"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running 10-fold CV for Random Forest...\n",
      "\n",
      "Running 10-fold CV for SVM...\n",
      "\n",
      "Running 10-fold CV for XGBoost...\n",
      "\n",
      "Running 10-fold CV for Ensemble...\n",
      "\n",
      "Cross-Validation Results (10-fold):\n",
      "        Model  Threshold  Accuracy  Precision  Recall  F1 Score  ROC AUC  Positive Rate  Std Accuracy   Std F1\n",
      "Random Forest       0.44     0.880   0.925000    0.90  0.873333 0.883333          0.430      0.228254 0.205372\n",
      "          SVM       0.65     0.825   0.733333    0.70  0.683333 0.883333          0.325      0.191377 0.383333\n",
      "      XGBoost       0.47     0.775   0.791667    0.75  0.720000 0.875000          0.415      0.249249 0.308113\n",
      "     Ensemble       0.61     0.845   0.833333    0.75  0.750000 0.883333          0.345      0.176706 0.309570\n",
      "\n",
      "Aggregated Confusion Matrices (Sum across all folds):\n",
      "\n",
      "Random Forest (Threshold=0.44):\n",
      "[[24  3]\n",
      " [ 2 16]]\n",
      "\n",
      "SVM (Threshold=0.65):\n",
      "[[25  2]\n",
      " [ 6 12]]\n",
      "\n",
      "XGBoost (Threshold=0.47):\n",
      "[[22  5]\n",
      " [ 5 13]]\n",
      "\n",
      "Ensemble (Threshold=0.61):\n",
      "[[25  2]\n",
      " [ 5 13]]\n",
      "\n",
      "Final Evaluation on Test Set:\n",
      "        Model  Threshold  Accuracy  Precision   Recall  F1 Score  ROC AUC  Positive Rate  Std Accuracy  Std F1\n",
      "Random Forest       0.44  0.814815   0.914286 0.653061  0.761905 0.901072       0.324074           0.0     0.0\n",
      "          SVM       0.65  0.759259   1.000000 0.469388  0.638889 0.892771       0.212963           0.0     0.0\n",
      "      XGBoost       0.47  0.805556   0.850000 0.693878  0.764045 0.917330       0.370370           0.0     0.0\n",
      "     Ensemble       0.61  0.768519   0.928571 0.530612  0.675325 0.924939       0.259259           0.0     0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def cross_validate_model(model, X, y, model_name, threshold=0.5, n_splits=10):\n",
    "    \"\"\"\n",
    "    Perform stratified k-fold cross-validation with custom threshold\n",
    "\n",
    "    Parameters:\n",
    "    - model: Model object\n",
    "    - X: Features (numpy array or pandas DataFrame)\n",
    "    - y: Target (numpy array or pandas Series)\n",
    "    - model_name: Name of model\n",
    "    - threshold: Probability threshold\n",
    "    - n_splits: Number of cross-validation folds\n",
    "\n",
    "    Returns:\n",
    "    - Dictionary of mean metrics across all folds\n",
    "    - Full confusion matrix\n",
    "    \"\"\"\n",
    "    # Convert to numpy arrays if they're pandas objects\n",
    "    X_array = X.values if hasattr(X, 'values') else X\n",
    "    y_array = y.values if hasattr(y, 'values') else y\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    metrics = {\n",
    "        'Accuracy': [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'ROC AUC': [],\n",
    "        'Positive Rate': []\n",
    "    }\n",
    "    conf_matrices = []\n",
    "\n",
    "    for train_idx, test_idx in skf.split(X_array, y_array):\n",
    "        X_train, X_test = X_array[train_idx], X_array[test_idx]\n",
    "        y_train, y_test = y_array[train_idx], y_array[test_idx]\n",
    "\n",
    "        # Clone model to avoid refitting the same object\n",
    "        model_clone = clone(model)\n",
    "        model_clone.fit(X_train, y_train)\n",
    "\n",
    "        try:\n",
    "            y_prob = model_clone.predict_proba(X_test)[:, 1]\n",
    "            y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "            # Store metrics for this fold\n",
    "            metrics['Accuracy'].append(accuracy_score(y_test, y_pred))\n",
    "            metrics['Precision'].append(precision_score(y_test, y_pred, zero_division=0))\n",
    "            metrics['Recall'].append(recall_score(y_test, y_pred))\n",
    "            metrics['F1'].append(f1_score(y_test, y_pred))\n",
    "            metrics['ROC AUC'].append(roc_auc_score(y_test, y_prob))\n",
    "            metrics['Positive Rate'].append(y_pred.mean())\n",
    "            conf_matrices.append(confusion_matrix(y_test, y_pred))\n",
    "        except Exception as e:\n",
    "            print(f\"Error in fold: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    # Calculate mean metrics\n",
    "    mean_metrics = {\n",
    "        'Model': model_name,\n",
    "        'Threshold': threshold,\n",
    "        'Accuracy': np.mean(metrics['Accuracy']),\n",
    "        'Precision': np.mean(metrics['Precision']),\n",
    "        'Recall': np.mean(metrics['Recall']),\n",
    "        'F1 Score': np.mean(metrics['F1']),\n",
    "        'ROC AUC': np.mean(metrics['ROC AUC']),\n",
    "        'Positive Rate': np.mean(metrics['Positive Rate']),\n",
    "        'Confusion Matrix': sum(conf_matrices),  # Sum across all folds\n",
    "        'Std Accuracy': np.std(metrics['Accuracy']),\n",
    "        'Std F1': np.std(metrics['F1'])\n",
    "    }\n",
    "\n",
    "    return mean_metrics\n",
    "\n",
    "# Define custom thresholds for each model\n",
    "model_thresholds = {\n",
    "    'Random Forest': 0.44, #44\n",
    "    'SVM': 0.65, #60 -90, 65 -91\n",
    "    'XGBoost': 0.47,\n",
    "    'Ensemble': 0.61\n",
    "}\n",
    "\n",
    "# Perform cross-validation for each model\n",
    "cv_results = []\n",
    "for model_name, model in [('Random Forest', rf),\n",
    "                         ('SVM', svm),\n",
    "                         ('XGBoost', xgb),\n",
    "                         ('Ensemble', ensemble)]:\n",
    "    print(f\"\\nRunning 10-fold CV for {model_name}...\")\n",
    "    result = cross_validate_model(\n",
    "        model,\n",
    "        X_train_scaled,  # Using training data for CV\n",
    "        y_train,\n",
    "        model_name,\n",
    "        threshold=model_thresholds[model_name]\n",
    "    )\n",
    "    cv_results.append(result)\n",
    "\n",
    "# Create and display results DataFrame\n",
    "cv_df = pd.DataFrame(cv_results)\n",
    "print(\"\\nCross-Validation Results (10-fold):\")\n",
    "print(cv_df.drop(columns=['Confusion Matrix']).to_string(index=False))\n",
    "\n",
    "# Display aggregated confusion matrices\n",
    "print(\"\\nAggregated Confusion Matrices (Sum across all folds):\")\n",
    "for _, row in cv_df.iterrows():\n",
    "    print(f\"\\n{row['Model']} (Threshold={row['Threshold']}):\")\n",
    "    print(row['Confusion Matrix'])\n",
    "\n",
    "# Final test set evaluation\n",
    "print(\"\\nFinal Evaluation on Test Set:\")\n",
    "test_results = []\n",
    "for model_name, model in [('Random Forest', rf),\n",
    "                         ('SVM', svm),\n",
    "                         ('XGBoost', xgb),\n",
    "                         ('Ensemble', ensemble)]:\n",
    "    res = evaluate_model(\n",
    "        model,\n",
    "        X_test_scaled,\n",
    "        y_test,\n",
    "        model_name,\n",
    "        threshold=model_thresholds[model_name]\n",
    "    )\n",
    "    if res is not None:\n",
    "        test_results.append(res)\n",
    "\n",
    "test_df = pd.DataFrame(test_results)\n",
    "print(test_df.drop(columns=['Confusion Matrix']).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 86\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# Perform CV\u001b[39;00m\n\u001b[0;32m     85\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 86\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, model \u001b[38;5;129;01min\u001b[39;00m [(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRandom Forest\u001b[39m\u001b[38;5;124m'\u001b[39m, rf), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSVM\u001b[39m\u001b[38;5;124m'\u001b[39m, svm), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mXGBoost\u001b[39m\u001b[38;5;124m'\u001b[39m, xgb), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnsemble\u001b[39m\u001b[38;5;124m'\u001b[39m, ensemble)]:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mRunning 10-fold CV for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     88\u001b[0m     result \u001b[38;5;241m=\u001b[39m cross_validate_model(model, X_train_scaled, y_train, model_name, threshold\u001b[38;5;241m=\u001b[39mmodel_thresholds[model_name])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rf' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Evaluation function for test set\n",
    "def evaluate_model(model, X_test, y_test, model_name, threshold=0.5):\n",
    "    try:\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "        return {\n",
    "            'Model': model_name,\n",
    "            'Threshold': threshold,\n",
    "            'Accuracy': accuracy_score(y_test, y_pred),\n",
    "            'Precision': precision_score(y_test, y_pred, zero_division=0),\n",
    "            'Recall': recall_score(y_test, y_pred),\n",
    "            'F1 Score': f1_score(y_test, y_pred),\n",
    "            'ROC AUC': roc_auc_score(y_test, y_prob),\n",
    "            'Positive Rate': y_pred.mean(),\n",
    "            'Confusion Matrix': confusion_matrix(y_test, y_pred),\n",
    "            'Std Accuracy': 0.0,  # Not applicable here\n",
    "            'Std F1': 0.0  # Not applicable here\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating {model_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Cross-validation function\n",
    "def cross_validate_model(model, X, y, model_name, threshold=0, n_splits=10):\n",
    "    X_array = X.values if hasattr(X, 'values') else X\n",
    "    y_array = y.values if hasattr(y, 'values') else y\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    metrics = {k: [] for k in ['Accuracy', 'Precision', 'Recall', 'F1', 'ROC AUC', 'Positive Rate']}\n",
    "    conf_matrices = []\n",
    "\n",
    "    for train_idx, test_idx in skf.split(X_array, y_array):\n",
    "        X_train, X_test = X_array[train_idx], X_array[test_idx]\n",
    "        y_train, y_test = y_array[train_idx], y_array[test_idx]\n",
    "\n",
    "        model_clone = clone(model)\n",
    "        model_clone.fit(X_train, y_train)\n",
    "\n",
    "        try:\n",
    "            y_prob = model_clone.predict_proba(X_test)[:, 1]\n",
    "            y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "            metrics['Accuracy'].append(accuracy_score(y_test, y_pred))\n",
    "            metrics['Precision'].append(precision_score(y_test, y_pred, zero_division=0))\n",
    "            metrics['Recall'].append(recall_score(y_test, y_pred))\n",
    "            metrics['F1'].append(f1_score(y_test, y_pred))\n",
    "            metrics['ROC AUC'].append(roc_auc_score(y_test, y_prob))\n",
    "            metrics['Positive Rate'].append(y_pred.mean())\n",
    "            conf_matrices.append(confusion_matrix(y_test, y_pred))\n",
    "        except Exception as e:\n",
    "            print(f\"Error in fold: {e}\")\n",
    "\n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'Threshold': threshold,\n",
    "        'Accuracy': np.mean(metrics['Accuracy']),\n",
    "        'Precision': np.mean(metrics['Precision']),\n",
    "        'Recall': np.mean(metrics['Recall']),\n",
    "        'F1 Score': np.mean(metrics['F1']),\n",
    "        'ROC AUC': np.mean(metrics['ROC AUC']),\n",
    "        'Positive Rate': np.mean(metrics['Positive Rate']),\n",
    "        'Confusion Matrix': sum(conf_matrices),\n",
    "        'Std Accuracy': np.std(metrics['Accuracy']),\n",
    "        'Std F1': np.std(metrics['F1'])\n",
    "    }\n",
    "\n",
    "# Define thresholds\n",
    "model_thresholds = {\n",
    "    'Random Forest': 0.44,\n",
    "    'SVM': 0.65,\n",
    "    'XGBoost': 0.47,\n",
    "    'Ensemble': 0.61\n",
    "}\n",
    "\n",
    "# Perform CV\n",
    "cv_results = []\n",
    "for model_name, model in [('Random Forest', rf), ('SVM', svm), ('XGBoost', xgb), ('Ensemble', ensemble)]:\n",
    "    print(f\"\\nRunning 10-fold CV for {model_name}...\")\n",
    "    result = cross_validate_model(model, X_train_scaled, y_train, model_name, threshold=model_thresholds[model_name])\n",
    "    cv_results.append(result)\n",
    "\n",
    "cv_df = pd.DataFrame(cv_results)\n",
    "print(\"\\nCross-Validation Results (10-fold):\")\n",
    "print(cv_df.drop(columns=['Confusion Matrix']).to_string(index=False))\n",
    "\n",
    "# Plot confusion matrices\n",
    "print(\"\\nConfusion Matrices (Cross-Validation):\")\n",
    "for _, row in cv_df.iterrows():\n",
    "    cm = row['Confusion Matrix']\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f\"{row['Model']} (Threshold={row['Threshold']})\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Final test set evaluation\n",
    "print(\"\\nFinal Evaluation on Test Set:\")\n",
    "test_results = []\n",
    "for model_name, model in [('Random Forest', rf), ('SVM', svm), ('XGBoost', xgb), ('Ensemble', ensemble)]:\n",
    "    res = evaluate_model(model, X_test_scaled, y_test, model_name, threshold=model_thresholds[model_name])\n",
    "    if res:\n",
    "        test_results.append(res)\n",
    "\n",
    "test_df = pd.DataFrame(test_results)\n",
    "print(test_df.drop(columns=['Confusion Matrix']).to_string(index=False))\n",
    "\n",
    "# Plot test set confusion matrices\n",
    "print(\"\\nConfusion Matrices (Test Set):\")\n",
    "for _, row in test_df.iterrows():\n",
    "    cm = row['Confusion Matrix']\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Greens')\n",
    "    plt.title(f\"Test Set: {row['Model']} (Threshold={row['Threshold']})\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g1fTbano4H94",
    "outputId": "621e7064-785b-4014-e19d-e580b4d84ecb"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 17\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m'\u001b[39m: model_name,\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: accuracy_score(y_test, y_pred),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConfusion Matrix\u001b[39m\u001b[38;5;124m'\u001b[39m: confusion_matrix(y_test, y_pred)\n\u001b[0;32m     13\u001b[0m     }\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Evaluate all models\u001b[39;00m\n\u001b[0;32m     16\u001b[0m results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([\n\u001b[1;32m---> 17\u001b[0m     evaluate_model(rf, X_test_scaled, y_test, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRandom Forest\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     18\u001b[0m     evaluate_model(svm, X_test_scaled, y_test, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSVM\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     19\u001b[0m     evaluate_model(xgb, X_test_scaled, y_test, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mXGBoost\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     20\u001b[0m     evaluate_model(ensemble, X_test_scaled, y_test, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnsemble\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     21\u001b[0m ])\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mModel Evaluation Results:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(results\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConfusion Matrix\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rf' is not defined"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    y_pred = (model.predict_proba(X_test)[:, 1] >= 0.).astype(int)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall': recall_score(y_test, y_pred),\n",
    "        'F1 Score': f1_score(y_test, y_pred),\n",
    "        'ROC AUC': roc_auc_score(y_test, y_prob),\n",
    "        'Confusion Matrix': confusion_matrix(y_test, y_pred)\n",
    "    }\n",
    "\n",
    "# Evaluate all models\n",
    "results = pd.DataFrame([\n",
    "    evaluate_model(rf, X_test_scaled, y_test, 'Random Forest'),\n",
    "    evaluate_model(svm, X_test_scaled, y_test, 'SVM'),\n",
    "    evaluate_model(xgb, X_test_scaled, y_test, 'XGBoost'),\n",
    "    evaluate_model(ensemble, X_test_scaled, y_test, 'Ensemble')\n",
    "])\n",
    "\n",
    "print(\"\\nModel Evaluation Results:\")\n",
    "print(results.drop(columns=['Confusion Matrix']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wCKg2c0K9zzh",
    "outputId": "31c6bc73-9f7e-4175-dcd1-555619c3609a"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 254\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Saved predictions with SHAP explanations\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    251\u001b[0m \u001b[38;5;66;03m### Execution Workflow ###\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;66;03m# 1. Prepare models dict\u001b[39;00m\n\u001b[0;32m    253\u001b[0m models_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m--> 254\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRandom Forest\u001b[39m\u001b[38;5;124m'\u001b[39m: rf,\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSVM\u001b[39m\u001b[38;5;124m'\u001b[39m: svm,\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mXGBoost\u001b[39m\u001b[38;5;124m'\u001b[39m: xgb,\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnsemble\u001b[39m\u001b[38;5;124m'\u001b[39m: ensemble\n\u001b[0;32m    258\u001b[0m }\n\u001b[0;32m    260\u001b[0m \u001b[38;5;66;03m# 2. Get feature names\u001b[39;00m\n\u001b[0;32m    261\u001b[0m feature_names \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rf' is not defined"
     ]
    }
   ],
   "source": [
    "# Section 5: Final Robust SHAP Analysis (Complete Fixed Version)\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from warnings import filterwarnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Disable warnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "### 1. SHAP Initialization ###\n",
    "def initialize_shap_explainers(models_dict, X_train, feature_names):\n",
    "    \"\"\"Initialize SHAP explainers with proper shape handling\"\"\"\n",
    "    explainers = {}\n",
    "    print(\"Initializing SHAP explainers...\")\n",
    "\n",
    "    # Create background data\n",
    "    background = shap.sample(X_train, min(100, len(X_train)))\n",
    "\n",
    "    # Tree-based models\n",
    "    if 'Random Forest' in models_dict:\n",
    "        try:\n",
    "            explainers['Random Forest'] = shap.TreeExplainer(\n",
    "                models_dict['Random Forest'],\n",
    "                feature_perturbation=\"tree_path_dependent\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Random Forest explainer failed: {str(e)}\")\n",
    "            explainers['Random Forest'] = None\n",
    "\n",
    "    if 'XGBoost' in models_dict:\n",
    "        try:\n",
    "            explainers['XGBoost'] = shap.TreeExplainer(\n",
    "                models_dict['XGBoost'],\n",
    "                feature_perturbation=\"tree_path_dependent\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"❌ XGBoost explainer failed: {str(e)}\")\n",
    "            explainers['XGBoost'] = None\n",
    "\n",
    "    # SVM and Ensemble\n",
    "    if 'SVM' in models_dict:\n",
    "        try:\n",
    "            def svm_predict(X):\n",
    "                return models_dict['SVM'].predict_proba(X)\n",
    "\n",
    "            explainers['SVM'] = shap.KernelExplainer(\n",
    "                svm_predict,\n",
    "                background,\n",
    "                silent=True\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"❌ SVM explainer failed: {str(e)}\")\n",
    "            explainers['SVM'] = None\n",
    "\n",
    "    if 'Ensemble' in models_dict:\n",
    "        try:\n",
    "            def ensemble_predict(X):\n",
    "                return models_dict['Ensemble'].predict_proba(X)\n",
    "\n",
    "            explainers['Ensemble'] = shap.KernelExplainer(\n",
    "                ensemble_predict,\n",
    "                background,\n",
    "                silent=True\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Ensemble explainer failed: {str(e)}\")\n",
    "            explainers['Ensemble'] = None\n",
    "\n",
    "    print(\"✅ SHAP explainers initialized\")\n",
    "    return explainers\n",
    "\n",
    "### 2. SHAP Value Computation ###\n",
    "def compute_shap_values(explainers, X_test, feature_names, max_samples=100):\n",
    "    \"\"\"Compute SHAP values with proper shape handling\"\"\"\n",
    "    shap_values = {}\n",
    "    X_test_sample = X_test[:max_samples]\n",
    "\n",
    "    print(\"\\nComputing SHAP values...\")\n",
    "\n",
    "    for name, explainer in explainers.items():\n",
    "        if explainer is None:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            if isinstance(explainer, shap.TreeExplainer):\n",
    "                vals = explainer.shap_values(X_test_sample)\n",
    "                # Handle different tree explainer outputs\n",
    "                if isinstance(vals, list):\n",
    "                    # Binary classification - take class 1 values\n",
    "                    shap_values[name] = vals[1]\n",
    "                elif len(vals.shape) == 3:\n",
    "                    # Multi-class - take class 1 values\n",
    "                    shap_values[name] = vals[:, :, 1]\n",
    "                else:\n",
    "                    shap_values[name] = vals\n",
    "            else:\n",
    "                # For KernelExplainer (SVM/Ensemble)\n",
    "                vals = np.zeros((len(X_test_sample), len(feature_names)))\n",
    "\n",
    "                for i in tqdm(range(len(X_test_sample)), desc=f\"Computing {name} SHAP\"):\n",
    "                    sample_shap = explainer.shap_values(\n",
    "                        X_test_sample[i:i+1],\n",
    "                        silent=True,\n",
    "                        nsamples=200\n",
    "                    )\n",
    "\n",
    "                    # Handle both binary and multi-class cases\n",
    "                    if isinstance(sample_shap, list):\n",
    "                        vals[i] = sample_shap[1][0]  # Class 1 probabilities\n",
    "                    elif len(sample_shap.shape) == 3:\n",
    "                        vals[i] = sample_shap[0, :, 1]  # Class 1 for multi-class\n",
    "                    else:\n",
    "                        vals[i] = sample_shap[0]  # Single output\n",
    "\n",
    "                shap_values[name] = vals\n",
    "\n",
    "            # Validate shape\n",
    "            if shap_values[name].shape[1] != len(feature_names):\n",
    "                print(f\"⚠️ Adjusting {name} SHAP shape from {shap_values[name].shape} to match {len(feature_names)} features\")\n",
    "                if shap_values[name].shape[1] > len(feature_names):\n",
    "                    shap_values[name] = shap_values[name][:, :len(feature_names)]\n",
    "                else:\n",
    "                    padded = np.zeros((shap_values[name].shape[0], len(feature_names)))\n",
    "                    padded[:, :shap_values[name].shape[1]] = shap_values[name]\n",
    "                    shap_values[name] = padded\n",
    "\n",
    "            print(f\"✅ {name} SHAP computed - Shape: {shap_values[name].shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ {name} SHAP computation failed: {str(e)}\")\n",
    "            shap_values[name] = None\n",
    "\n",
    "    return shap_values, X_test_sample\n",
    "\n",
    "### 3. SHAP Visualization (Fixed for Random Forest) ###\n",
    "def generate_shap_visualizations(shap_values, feature_names, X_test):\n",
    "    \"\"\"Generate visualizations with robust error handling and show value impact\"\"\"\n",
    "    print(\"\\nGenerating SHAP visualizations...\")\n",
    "\n",
    "    sample_size = min(100, len(X_test))\n",
    "    X_sample = X_test[:sample_size]\n",
    "    X_df = pd.DataFrame(X_sample, columns=feature_names)\n",
    "\n",
    "    for name, values in shap_values.items():\n",
    "        if values is None:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Prepare SHAP values\n",
    "            sample_values = values[:sample_size]\n",
    "            if len(sample_values.shape) == 3:\n",
    "                sample_values = sample_values[:, :, 1]  # Class 1 only\n",
    "\n",
    "            ### 1. Summary Dot Plot ###\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            shap.summary_plot(\n",
    "                sample_values,\n",
    "                X_df,\n",
    "                show=False,\n",
    "                max_display=20\n",
    "            )\n",
    "            plt.title(f'{name} SHAP Summary (Dot)', pad=20)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"shap_{name.lower().replace(' ', '_')}_summary_dot.png\",\n",
    "                        bbox_inches='tight', dpi=150)\n",
    "            plt.close()\n",
    "\n",
    "            ### 2. Optional Bar Plot ###\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            shap.summary_plot(\n",
    "                sample_values,\n",
    "                X_df,\n",
    "                show=False,\n",
    "                plot_type='bar',\n",
    "                max_display=20\n",
    "            )\n",
    "            plt.title(f'{name} SHAP Summary (Bar)', pad=20)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"shap_{name.lower().replace(' ', '_')}_summary_bar.png\",\n",
    "                        bbox_inches='tight', dpi=150)\n",
    "            plt.close()\n",
    "\n",
    "            ### 3. Dependence Plots for Top Features ###\n",
    "            mean_abs = np.mean(np.abs(sample_values), axis=0)\n",
    "            top_idx = np.argsort(mean_abs)[-5:][::-1]  # Top 5 for detailed dependence\n",
    "\n",
    "            for idx in top_idx:\n",
    "                feature = feature_names[idx]\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                shap.dependence_plot(\n",
    "                    feature,\n",
    "                    sample_values,\n",
    "                    X_df,\n",
    "                    show=False\n",
    "                )\n",
    "                plt.title(f\"{name} Dependence Plot: {feature}\")\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f\"shap_{name.lower().replace(' ', '_')}_dependence_{feature}.png\",\n",
    "                            bbox_inches='tight', dpi=150)\n",
    "                plt.close()\n",
    "\n",
    "            ### 4. Custom Importance Plot ###\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            plt.barh(np.array(feature_names)[top_idx], mean_abs[top_idx])\n",
    "            plt.title(f'{name} Top Features')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"shap_{name.lower().replace(' ', '_')}_importance.png\",\n",
    "                        bbox_inches='tight', dpi=150)\n",
    "            plt.close()\n",
    "\n",
    "            print(f\"✅ Saved {name} visualizations (summary, bar, dependence)\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ {name} visualization failed: {str(e)}\")\n",
    "\n",
    "### 4. Update CSV with SHAP ###\n",
    "def update_csv_with_shap(df, shap_values, feature_names, X_test_sample, models_dict):\n",
    "    \"\"\"Add SHAP explanations to CSV\"\"\"\n",
    "    print(\"\\nUpdating CSV with SHAP explanations...\")\n",
    "\n",
    "    df_out = df.iloc[:len(X_test_sample)].copy()\n",
    "\n",
    "    # Add predictions\n",
    "    for name, model in models_dict.items():\n",
    "        df_out[f\"{name.lower()}_prob\"] = model.predict_proba(X_test_sample)[:, 1]\n",
    "        df_out[f\"{name.lower()}_pred\"] = (df_out[f\"{name.lower()}_prob\"] >= 0.5).astype(int)\n",
    "\n",
    "    # Add SHAP explanations\n",
    "    for name, values in shap_values.items():\n",
    "        if values is None:\n",
    "            continue\n",
    "\n",
    "        explanations = []\n",
    "        for i in range(len(X_test_sample)):\n",
    "            # Ensure we have 1D array\n",
    "            sample_values = values[i] if len(values.shape) == 2 else values[i, :, 1]\n",
    "\n",
    "            # Get top 3 features\n",
    "            top3_idx = np.argsort(np.abs(sample_values))[-3:][::-1]\n",
    "            explanation = \", \".join([\n",
    "                f\"{feature_names[j]} ({'↑' if sample_values[j] > 0 else '↓'}{abs(sample_values[j]):.3f})\"\n",
    "                for j in top3_idx\n",
    "            ])\n",
    "            explanations.append(explanation)\n",
    "\n",
    "        df_out[f\"{name.lower()}_explanation\"] = explanations\n",
    "\n",
    "    df_out.to_csv('final_predictions_with_shap.csv', index=False)\n",
    "    print(\"✅ Saved predictions with SHAP explanations\")\n",
    "\n",
    "### Execution Workflow ###\n",
    "# 1. Prepare models dict\n",
    "models_dict = {\n",
    "    'Random Forest': rf,\n",
    "    'SVM': svm,\n",
    "    'XGBoost': xgb,\n",
    "    'Ensemble': ensemble\n",
    "}\n",
    "\n",
    "# 2. Get feature names\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "# 3. Initialize explainers\n",
    "explainers = initialize_shap_explainers(models_dict, X_train_scaled, feature_names)\n",
    "\n",
    "# 4. Compute SHAP values\n",
    "shap_values, X_test_sample = compute_shap_values(\n",
    "    explainers,\n",
    "    X_test_scaled,\n",
    "    feature_names,\n",
    "    max_samples=100\n",
    ")\n",
    "\n",
    "# 5. Generate visualizations\n",
    "generate_shap_outputs(shap_values, feature_names, X_test_sample)\n",
    "\n",
    "# 6. Update CSV\n",
    "update_csv_with_shap(df, shap_values, feature_names, X_test_sample, models_dict)\n",
    "\n",
    "print(\"\\n✔️ SHAP analysis completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WXOKF5-FGv-Z",
    "outputId": "07879ebc-f33f-4d79-d3b4-8d787e66d057"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features (67): ['domain_length', 'has_subdomain', 'num_dots', 'num_hyphens', 'num_slash']...\n",
      "Initializing SHAP explainers...\n",
      "✅ SHAP explainers initialized\n",
      "\n",
      "Computing SHAP values...\n",
      "✅ Random Forest SHAP computed - Shape: (108, 67, 2)\n",
      "✅ XGBoost SHAP computed - Shape: (108, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing SVM SHAP: 100%|████████████████████████████████████████████████████████████| 108/108 [00:49<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ SVM SHAP computed - Shape: (108, 67)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Ensemble SHAP: 100%|███████████████████████████████████████████████████████| 108/108 [01:08<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Ensemble SHAP computed - Shape: (108, 67)\n",
      "\n",
      "Generating SHAP visualizations...\n",
      "✅ Saved Random Forest visualizations\n",
      "✅ Saved XGBoost visualizations\n",
      "✅ Saved SVM visualizations\n",
      "✅ Saved Ensemble visualizations\n",
      "\n",
      "Exporting full results...\n",
      "✅ Saved full results to 'full_predictions_with_shap.csv'\n",
      "✅ Saved sample results to 'sample_predictions_with_shap.csv'\n",
      "\n",
      "✔️ Analysis completed successfully!\n",
      "\n",
      "Sample of explanations:\n",
      "                                               domain  \\\n",
      "1   www.dghjdgf.com/paypal.co.uk/cycgi-bin/webscrc...   \n",
      "4   thewhiskeydregs.com/wp-content/themes/widescre...   \n",
      "9   horizonsgallery.com/js/bin/ssl1/_id/www.paypal...   \n",
      "11  docs.google.com/spreadsheet/viewform?formkey=d...   \n",
      "21  optimistic-pessimism.com/aoluserupdatealert.in...   \n",
      "26  jameshowardmusic.com/wp-content/themes/widescr...   \n",
      "27                                       xini.eu/00Qe   \n",
      "31  horizonsgallery.com/js/bin/ssl/_id/www.paypal....   \n",
      "36  docs.google.com/a/unmsm.edu.pe/spreadsheet/vie...   \n",
      "40                  stthomasedu.ucoz.ua/microsoft.htm   \n",
      "\n",
      "                            Random Forest_explanation  \\\n",
      "1   title_length (↑0.045), digit_ratio (↓0.031), h...   \n",
      "4   num_question (↑0.064), full_url_length (↓0.043...   \n",
      "9   num_dots (↑0.059), digit_ratio (↓0.039), has_r...   \n",
      "11  http_status (↑0.044), domain_age_days (↓0.040)...   \n",
      "21  full_url_length (↓0.050), http_status (↓0.044)...   \n",
      "26  http_status (↑0.066), full_url_length (↓0.043)...   \n",
      "27  domain_age_days (↑0.055), full_url_length (↓0....   \n",
      "31  full_url_length (↓0.062), http_status (↑0.050)...   \n",
      "36  full_url_length (↓0.057), domain_age_days (↑0....   \n",
      "40  domain_age_days (↑0.066), http_status (↑0.064)...   \n",
      "\n",
      "                                  XGBoost_explanation  \\\n",
      "1   http_status (↓1.671), num_dots (↑0.732), domai...   \n",
      "4   http_status (↓1.701), num_question (↑1.317), f...   \n",
      "9   http_status (↑1.646), domain_age_days (↓0.842)...   \n",
      "11  http_status (↑1.594), domain_age_days (↓0.842)...   \n",
      "21  http_status (↓1.802), full_url_length (↓0.827)...   \n",
      "26  http_status (↑1.768), full_url_length (↓0.748)...   \n",
      "27  http_status (↓2.047), full_url_length (↓0.746)...   \n",
      "31  http_status (↑1.646), full_url_length (↓1.246)...   \n",
      "36  http_status (↓1.712), full_url_length (↓0.819)...   \n",
      "40  http_status (↑1.824), num_dots (↑0.713), num_l...   \n",
      "\n",
      "                                      SVM_explanation  \\\n",
      "1   num_images (↑0.057), title_length (↑0.037), dn...   \n",
      "4   num_question (↑0.053), has_redirect (↑0.036), ...   \n",
      "9   has_redirect (↑0.088), domain_age_days (↓0.040...   \n",
      "11  dns_cname_count (↓0.043), dns_cname_presence (...   \n",
      "21  has_ssl (↓0.039), has_digits (↑0.037), http_st...   \n",
      "26  http_status (↑0.065), has_ssl (↓0.040), has_di...   \n",
      "27  domain_age_days (↑0.086), title_length (↑0.043...   \n",
      "31  dns_ns_presence (↑0.034), http_status (↑0.033)...   \n",
      "36  dns_mx_count (↑0.061), has_digits (↓0.041), nu...   \n",
      "40  domain_age_days (↑0.079), domain_length (↑0.06...   \n",
      "\n",
      "                                 Ensemble_explanation  \n",
      "1   http_status (↓0.084), title_length (↑0.031), f...  \n",
      "4   http_status (↓0.072), num_question (↑0.055), n...  \n",
      "9   http_status (↑0.079), num_dots (↑0.063), domai...  \n",
      "11  http_status (↑0.092), domain_age_days (↓0.050)...  \n",
      "21  http_status (↓0.090), full_url_length (↓0.049)...  \n",
      "26  http_status (↑0.113), full_url_length (↓0.052)...  \n",
      "27  http_status (↓0.100), domain_age_days (↑0.047)...  \n",
      "31  full_url_length (↓0.087), http_status (↑0.071)...  \n",
      "36  http_status (↓0.090), has_favicon (↓0.036), fu...  \n",
      "40  http_status (↑0.132), domain_age_days (↑0.057)...  \n"
     ]
    }
   ],
   "source": [
    "# Final Corrected SHAP Analysis\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from warnings import filterwarnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Disable warnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "### 1. SHAP Initialization (Fixed for Tree Models) ###\n",
    "def initialize_shap_explainers(models_dict, X_train, feature_names):\n",
    "    \"\"\"Initialize SHAP explainers with correct configurations\"\"\"\n",
    "    explainers = {}\n",
    "    print(\"Initializing SHAP explainers...\")\n",
    "\n",
    "    # Background data for KernelExplainer\n",
    "    background = shap.sample(X_train, min(50, len(X_train)))\n",
    "\n",
    "    # Tree-based models (with correct parameters)\n",
    "    if 'Random Forest' in models_dict:\n",
    "        try:\n",
    "            explainers['Random Forest'] = shap.TreeExplainer(\n",
    "                models_dict['Random Forest'],\n",
    "                feature_perturbation=\"tree_path_dependent\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Random Forest explainer failed: {str(e)}\")\n",
    "\n",
    "    if 'XGBoost' in models_dict:\n",
    "        try:\n",
    "            explainers['XGBoost'] = shap.TreeExplainer(\n",
    "                models_dict['XGBoost'],\n",
    "                feature_perturbation=\"tree_path_dependent\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"❌ XGBoost explainer failed: {str(e)}\")\n",
    "\n",
    "    # SVM and Ensemble\n",
    "    if 'SVM' in models_dict:\n",
    "        try:\n",
    "            explainers['SVM'] = shap.KernelExplainer(\n",
    "                lambda X: models_dict['SVM'].predict_proba(X)[:, 1],  # Only class 1 probabilities\n",
    "                background,\n",
    "                silent=True\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"❌ SVM explainer failed: {str(e)}\")\n",
    "\n",
    "    if 'Ensemble' in models_dict:\n",
    "        try:\n",
    "            explainers['Ensemble'] = shap.KernelExplainer(\n",
    "                lambda X: models_dict['Ensemble'].predict_proba(X)[:, 1],  # Only class 1 probabilities\n",
    "                background,\n",
    "                silent=True\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Ensemble explainer failed: {str(e)}\")\n",
    "\n",
    "    print(\"✅ SHAP explainers initialized\")\n",
    "    return {k: v for k, v in explainers.items() if v is not None}\n",
    "\n",
    "### 2. SHAP Value Computation (Fixed Shape Handling) ###\n",
    "def compute_shap_values(explainers, X_test, feature_names):\n",
    "    \"\"\"Compute SHAP values with proper shape handling\"\"\"\n",
    "    shap_values = {}\n",
    "    print(\"\\nComputing SHAP values...\")\n",
    "\n",
    "    for name, explainer in explainers.items():\n",
    "        try:\n",
    "            if isinstance(explainer, shap.TreeExplainer):\n",
    "                # For tree models, get values and ensure correct shape\n",
    "                vals = explainer.shap_values(X_test)\n",
    "                if isinstance(vals, list):\n",
    "                    shap_values[name] = vals[1]  # Class 1 for binary classification\n",
    "                else:\n",
    "                    shap_values[name] = vals\n",
    "            else:\n",
    "                # For KernelExplainer, process samples individually\n",
    "                vals = np.zeros((len(X_test), len(feature_names)))\n",
    "\n",
    "                for i in tqdm(range(len(X_test)), desc=f\"Computing {name} SHAP\"):\n",
    "                    sample_shap = explainer.shap_values(\n",
    "                        X_test[i:i+1],\n",
    "                        silent=True,\n",
    "                        nsamples=100\n",
    "                    )\n",
    "                    vals[i] = sample_shap[0] if isinstance(sample_shap, np.ndarray) else sample_shap\n",
    "\n",
    "                shap_values[name] = vals\n",
    "\n",
    "            print(f\"✅ {name} SHAP computed - Shape: {shap_values[name].shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ {name} SHAP computation failed: {str(e)}\")\n",
    "            shap_values[name] = None\n",
    "\n",
    "    return {k: v for k, v in shap_values.items() if v is not None}\n",
    "\n",
    "### 3. Visualization (Fixed for All Models) ###\n",
    "def generate_shap_visualizations(shap_values, feature_names, X_test):\n",
    "    \"\"\"Generate visualizations with robust error handling\"\"\"\n",
    "    print(\"\\nGenerating SHAP visualizations...\")\n",
    "\n",
    "    # Use first 100 samples or all if fewer\n",
    "    sample_size = min(100, len(X_test))\n",
    "    X_sample = X_test[:sample_size]\n",
    "\n",
    "    for name, values in shap_values.items():\n",
    "        if values is None:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Prepare sample values\n",
    "            sample_values = values[:sample_size]\n",
    "            if len(sample_values.shape) == 3:\n",
    "                sample_values = sample_values[:, :, 1]  # Class 1 for 3D arrays\n",
    "\n",
    "            # 1. Summary Plot\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            shap.summary_plot(\n",
    "                sample_values,\n",
    "                pd.DataFrame(X_sample, columns=feature_names),\n",
    "                show=False,\n",
    "                max_display=20\n",
    "            )\n",
    "            plt.title(f'{name} Feature Importance', pad=20)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"shap_{name.lower().replace(' ', '_')}_summary.png\",\n",
    "                      bbox_inches='tight', dpi=150)\n",
    "            plt.close()\n",
    "\n",
    "            # 2. Custom Importance Plot\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            mean_abs = np.mean(np.abs(sample_values), axis=0)\n",
    "            top_idx = np.argsort(mean_abs)[-20:][::-1]\n",
    "            plt.barh(np.array(feature_names)[top_idx], mean_abs[top_idx])\n",
    "            plt.title(f'{name} Top Features')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"shap_{name.lower().replace(' ', '_')}_importance.png\",\n",
    "                      bbox_inches='tight', dpi=150)\n",
    "            plt.close()\n",
    "\n",
    "            print(f\"✅ Saved {name} visualizations\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ {name} visualization failed: {str(e)}\")\n",
    "\n",
    "### 4. Full Dataset Export (Fixed Length Mismatch) ###\n",
    "def export_full_results(df, shap_values, feature_names, X_test, models_dict):\n",
    "    \"\"\"Export complete results with proper formatting\"\"\"\n",
    "    print(\"\\nExporting full results...\")\n",
    "\n",
    "    # Ensure we're working with the correct subset of data\n",
    "    result_df = df.iloc[:len(X_test)].copy()\n",
    "\n",
    "    # Add predictions\n",
    "    for name, model in models_dict.items():\n",
    "        try:\n",
    "            result_df[f\"{name}_prob\"] = model.predict_proba(X_test)[:, 1]\n",
    "            result_df[f\"{name}_pred\"] = (result_df[f\"{name}_prob\"] >= 0.5).astype(int)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error adding predictions for {name}: {str(e)}\")\n",
    "\n",
    "    # Add SHAP explanations\n",
    "    for name, values in shap_values.items():\n",
    "        if values is None:\n",
    "            continue\n",
    "\n",
    "        explanations = []\n",
    "        for i in range(len(X_test)):\n",
    "            try:\n",
    "                if len(values.shape) == 3:\n",
    "                    sample_values = values[i, :, 1]  # Class 1 for 3D arrays\n",
    "                else:\n",
    "                    sample_values = values[i]\n",
    "\n",
    "                top3 = np.argsort(np.abs(sample_values))[-3:][::-1]\n",
    "                parts = []\n",
    "                for idx in top3:\n",
    "                    val = sample_values[idx]\n",
    "                    arrow = \"↑\" if val > 0 else \"↓\"\n",
    "                    parts.append(f\"{feature_names[idx]} ({arrow}{abs(val):.3f})\")\n",
    "                explanations.append(\", \".join(parts))\n",
    "            except Exception as e:\n",
    "                explanations.append(f\"Error: {str(e)}\")\n",
    "                print(f\"⚠️ Explanation error for {name} sample {i}: {str(e)}\")\n",
    "\n",
    "        result_df[f\"{name}_explanation\"] = explanations\n",
    "\n",
    "    # Save results\n",
    "    result_df.to_csv('full_predictions_with_shap.csv', index=False)\n",
    "    result_df.head(20).to_csv('sample_predictions_with_shap.csv', index=False)\n",
    "\n",
    "    print(\"✅ Saved full results to 'full_predictions_with_shap.csv'\")\n",
    "    print(\"✅ Saved sample results to 'sample_predictions_with_shap.csv'\")\n",
    "\n",
    "    return result_df\n",
    "\n",
    "### Execution Workflow ###\n",
    "# 1. Prepare models\n",
    "models_dict = {\n",
    "    'Random Forest': rf,\n",
    "    'SVM': svm,\n",
    "    'XGBoost': xgb,\n",
    "    'Ensemble': ensemble\n",
    "}\n",
    "\n",
    "# 2. Get feature names\n",
    "feature_names = X.columns.tolist()\n",
    "print(f\"\\nFeatures ({len(feature_names)}): {feature_names[:5]}...\")\n",
    "\n",
    "# 3. Initialize explainers with correct parameters\n",
    "explainers = initialize_shap_explainers(models_dict, X_train_scaled, feature_names)\n",
    "\n",
    "# 4. Compute SHAP values with proper shape handling\n",
    "shap_values = compute_shap_values(explainers, X_test_scaled, feature_names)\n",
    "\n",
    "# 5. Generate visualizations (using sample)\n",
    "generate_shap_visualizations(shap_values, feature_names, X_test_scaled)\n",
    "\n",
    "# 6. Export full results with proper data alignment\n",
    "final_results = export_full_results(df, shap_values, feature_names, X_test_scaled, models_dict)\n",
    "\n",
    "print(\"\\n✔️ Analysis completed successfully!\")\n",
    "print(\"\\nSample of explanations:\")\n",
    "print(final_results[['domain'] + [c for c in final_results.columns if 'explanation' in c]].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVKJ5wia2zzu"
   },
   "source": [
    "# New Section"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.13 (Fixed)",
   "language": "python",
   "name": "python313"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
